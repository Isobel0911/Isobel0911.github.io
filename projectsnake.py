# -*- coding: utf-8 -*-
"""ProjectSnake.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tpQXEDoHB1d71B4WXl3bOAESfFyEDsBB
"""

from google.colab import drive
drive.mount('/content/drive')
import os
!ls
os.chdir("drive/MyDrive/Snake Images")
!ls

import torchvision
import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import OrdinalEncoder

train_x = []
train_y = []
test_x = []
test_y = []

filenames = [name for name in os.listdir("train/Non Venomous")]

for filename in filenames:
    img = torchvision.io.read_image('train/Non Venomous/' + filename)
    if img.shape[0] != 3 or img.shape[1] != 400 or img.shape[2] != 400:
        continue
    img = torchvision.transforms.Grayscale()(img)
    img = torchvision.transforms.Resize((40,40))(img)
    img = img.flatten()
    train_x.append(img)
    train_y.append(0)

filenames = [name for name in os.listdir("train/Venomous")]

for filename in filenames:
    img = torchvision.io.read_image('train/Venomous/' + filename)
    if img.shape[0] != 3 or img.shape[1] != 400 or img.shape[2] != 400:
        continue
    img = torchvision.transforms.Grayscale()(img)
    img = torchvision.transforms.Resize((40,40))(img)
    img = img.flatten()
    train_x.append(img)
    train_y.append(1)
    

filenames = [name for name in os.listdir("test/Non Venomous")]

for filename in filenames:
    img = torchvision.io.read_image('test/Non Venomous/' + filename)
    if img.shape[0] != 3 or img.shape[1] != 400 or img.shape[2] != 400:
        continue
    img = torchvision.transforms.Grayscale()(img)
    img = torchvision.transforms.Resize((40,40))(img)
    img = img.flatten()
    test_x.append(img)
    test_y.append(0)


filenames = [name for name in os.listdir("test/Venomous")]

for filename in filenames:
    img = torchvision.io.read_image('test/Venomous/' + filename)
    if img.shape[0] != 3 or img.shape[1] != 400 or img.shape[2] != 400:
        continue
    img = torchvision.transforms.Grayscale()(img)
    img = torchvision.transforms.Resize((40,40))(img)
    img = img.flatten()
    test_x.append(img)
    test_y.append(1)

train_x, train_y = torch.stack(train_x), torch.tensor(train_y, dtype=torch.long)
test_x, test_y = torch.stack(test_x), torch.tensor(test_y, dtype=torch.long)
train_x = train_x / 255
test_x = test_x / 255

train_shuffle_order = torch.randperm(len(train_x))
train_shuffle_order = train_shuffle_order.tolist()

train_x = train_x[train_shuffle_order].cuda()
train_y = train_y[train_shuffle_order].cuda()
test_x = test_x.cuda()
test_y = test_y.cuda()

print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)

import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 64, 3)
        self.pool = nn.MaxPool2d(4, 4)
        self.bn1 = nn.BatchNorm2d(64)
        self.bn2 = nn.BatchNorm2d(8)
        self.conv2 = nn.Conv2d(64, 8, 3)
        # self.conv3 = nn.Conv2d(16, 16, 3)
        # self.conv4 = nn.Conv2d(16, 16, 3)
        # self.conv5 = nn.Conv2d(16, 16, 3)
        # self.conv6 = nn.Conv2d(16, 16, 3)
        # self.conv7 = nn.Conv2d(16, 16, 3)
        # self.conv8 = nn.Conv2d(16, 3, 3)
        self.fc1 = nn.Linear(392, 16)
        self.fc2 = nn.Linear(16, 2)
        self.dropout = torch.nn.Dropout(0.4)

    def forward(self, x):
        x = F.leaky_relu(self.conv1(x))
        x = self.bn1(x)
        x = self.dropout(x)
        x = self.pool(x)
        x = F.leaky_relu(self.conv2(x))
        x = self.bn2(x)
        x = self.dropout(x)
        # x = self.pool(x)
        # x = F.leaky_relu(self.conv3(x))
        # x = self.pool(x)
        # x = F.leaky_relu(self.conv4(x))
        # x = self.pool(x)
        # x = F.leaky_relu(self.conv5(x))
        # x = F.leaky_relu(self.conv6(x))
        # x = self.pool(x)
        # x = F.leaky_relu(self.conv7(x))
        # x = F.leaky_relu(self.conv8(x))
        # x = self.pool(x)
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = F.leaky_relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x


net = Net().cuda()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=0.001)

del net
del optimizer
del outputs
del inputs
del labels
del loss
torch.cuda.empty_cache()

train_loss = []
test_loss = []
batch_size = 64

def test():
    running_loss = 0.0
    count = 0
    samples = 0
    net.eval()
    batch_count = len(test_x) // batch_size
    for i in range(batch_count):
        inputs = test_x[batch_size * i : batch_size * (i + 1)]
        labels = test_y[batch_size * i : batch_size * (i + 1)]
        optimizer.zero_grad()
        outputs = net(inputs)
        yhat = torch.argmax(outputs.detach(), axis=-1)
        count += torch.sum((yhat == labels)).detach()
        loss = criterion(outputs, labels)
        outputs = outputs.detach()
        loss = loss.detach()
        running_loss += loss.item() * len(inputs)
        samples += len(inputs)
    inputs = test_x[batch_size * (i + 1):]
    labels = test_y[batch_size * (i + 1):]
    optimizer.zero_grad()
    outputs = net(inputs)
    yhat = torch.argmax(outputs.detach(), axis=-1)
    count += torch.sum((yhat == labels)).detach()
    loss = criterion(outputs, labels)
    outputs = outputs.detach()
    loss = loss.detach()
    running_loss += loss.item() * len(inputs)
    samples += len(inputs)
    test_loss.append(running_loss)
    print("test", "loss", running_loss/samples, "accuracy", 100*count/samples)

for epoch in range(100):  # loop over the dataset multiple times
    running_loss = 0.0
    count = 0
    samples = 0
    net.train()
    batch_count = len(train_x) // batch_size
    train_shuffle_order = torch.randperm(len(train_x))
    train_shuffle_order = train_shuffle_order.tolist()
    for i in range(batch_count):
        inds = train_shuffle_order[batch_size * i : batch_size * (i + 1)]
        inputs = train_x[inds]
        labels = train_y[inds]
        optimizer.zero_grad()
        outputs = net(inputs)
        yhat = torch.argmax(outputs.detach(), axis=-1)
        count += torch.sum((yhat == labels)).detach()
        loss = criterion(outputs, labels) * len(inputs)
        outputs = outputs.detach()
        loss.backward()
        optimizer.step()
        loss = loss.detach()
        running_loss += loss.item()
        samples += len(inputs)
    train_loss.append(running_loss)
    print(epoch, "loss", running_loss / samples, "accuracy", 100*count/samples)
    test()



plt.plot(range(len(train_loss)), train_loss)
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()
plt.plot(range(len(test_loss)), test_loss)
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()
test()